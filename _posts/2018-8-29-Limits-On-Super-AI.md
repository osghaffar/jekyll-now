---
layout: post
mathjax: true
title: What Limits the Emergence of Super AI?
---
I thought that I would switch up the mood from technical to theoretical. The question is, what's impeding the emergence of 
Super AIs - in other words, why don't we have extremely intelligent AIs like HAL 9000 from _2001: A Space Odyssey_, or
Cortana from _Halo_ - ones that can assist us in our daily lives and have the potential to learn almost anything. This is my
take on it.

For me, the answer has two parts: there are algorithmic and there are architectural limitations.

#### The Algorithmic Issue
---------------------------
Currently, the state-of-the-art algorithms use something called (deep) ***reinforcement learning***, which attempts to mimic the way that animals and humans learn new things - by trying something, receiving either positive or negative feedback, adjusting, and trying again. This was most <a href="https://deepmind.com/research/publications/playing-atari-deep-reinforcement-learning/">famously demonstrated</a> by Google's DeepMind and is currently being studied by OpenAI as well. 
It showed the ability of an AI to replicate or even surpass a human's ability at certain arcade games. 

However, as widely studied as deep reinforcement learning is, and despite the success it has achieved, there are some serious limitations.
